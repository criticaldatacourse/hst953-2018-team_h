---
title: "Visualisation_mit"
author: "Amita Ketkar"
date: "11/1/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(dplyr)
```

## R Markdown
For setting working directory (make sure where all your files are)
```{r}
setwd(getwd())
Gender<- (read_csv("gender.csv" ))
Height <- (read_csv("height.csv"))
Weight<- (read_csv("weight.csv"))
Age <- (read_csv("age.csv"))
df <- data.frame(Gender)
df1 <- data.frame(Weight)
```

For histogram of Fluid intake
```{r}

Gender %>% filter(total_ns_cv <8000)%>%
  ggplot(aes(x = total_ns_cv)) +
  geom_histogram(color = "black") +
  xlab("Total fluid distribution") +
  ggtitle("Preliminary exploration")
```

For histogram of hemoglobin recorded
```{r}
Gender %>% 
  ggplot(aes(x = HEMOGLOBIN_1st)) +
  geom_histogram(color = "black") +
  xlab("hgb distribution baseline") +
  ggtitle("Preliminary exploration")


```
 Check if the Hmoglobin after 36 hours distribution
```{r}
Gender %>% 
  ggplot(aes(x = hemoglobin_36)) +
  geom_histogram(color = "black") +
  xlab("hgb distribution baseline") +
  ggtitle("Preliminary exploration")

# sd(df1$hemoglobin_24)
# mean(df1$hemoglobin_24)
# max(df1$hemoglobin_24)
# 
 Gender %>% 
  ggplot(aes(x = hgb_difference)) +
  geom_histogram(color = "black") +
#   #scale_x_continuous(breaks = c(0.2,0.1,0,-0.1,-0.2,-0.3,-0.4,-0.5,-0.6,-0.7,-0.8,-0.9,-1.0,-1.1,-1.2,-1.3,-1.4,-1.5,-1.6,-1.7,-1.8,-1.9,-2.0,-2.1,-2.2,-2.3,-2.4,-2.5,-2.6,-2.7,-2.8,-2.9,-3.0,-3.1,-3.2,-3.3,-3.4,-3.5,-3.6,-3.7,-3.8,-3.9,-4.0,-4.1,-4.2,-4.3,-4.4,-4.5,-4.6,-4.7,-4.8,-4.9,-5.0,-5.1,-5.2,-5.3,-5.4,-5.5,-5.6,-5.7,-5.8,-5.9,-6.0,-6.1,-6.2,-6.3,-6.4,-6.5,-6.6,-6.7,-6.8,-6.9,-7.0))+
  ggtitle("Preliminary exploration")
#   #theme(axis.text.x = element_text(angle= 90, size = 5))
# 
# 
# # df1$transformedhgb <- 1/(df1$hgb_difference) 
# # 
# # df1 %>% 
# #   ggplot(aes(x = transformedhgb)) +
# #   geom_histogram(color = "black") +
# #   #scale_x_continuous(breaks = c(0.2,0.1,0,-0.1,-0.2,-0.3,-0.4,-0.5,-0.6,-0.7,-0.8,-0.9,-1.0,-1.1,-1.2,-1.3,-1.4,-1.5,-1.6,-1.7,-1.8,-1.9,-2.0,-2.1,-2.2,-2.3,-2.4,-2.5,-2.6,-2.7,-2.8,-2.9,-3.0,-3.1,-3.2,-3.3,-3.4,-3.5,-3.6,-3.7,-3.8,-3.9,-4.0,-4.1,-4.2,-4.3,-4.4,-4.5,-4.6,-4.7,-4.8,-4.9,-5.0,-5.1,-5.2,-5.3,-5.4,-5.5,-5.6,-5.7,-5.8,-5.9,-6.0,-6.1,-6.2,-6.3,-6.4,-6.5,-6.6,-6.7,-6.8,-6.9,-7.0))+
# #   ggtitle("Preliminary exploration")+
#   theme(axis.text.x = element_text(angle= 90, size = 5))
```

 For evaluation association between the hemoglobin at baseline and fluid given
 
```{r}
# sanity check . get the values of hemoglobin for a patient and plot the values over time 
# Hgb remain stable over time or there is change over time 
# saline by weight of person 

Gender %>% filter(total_ns_cv <8000)%>%
  ggplot(aes(x = hgb_difference, y= total_ns_cv)) +
  geom_point(color = "black") +
  xlab("difference") +
  ylab("total fluid")+
  ggtitle("Preliminary exploration")
```

Run a regressin and check for association 
```{r}
Gender1<- Gender %>% filter(total_ns_cv <8000) 
fit<-(lm( hgb_difference ~ total_ns_cv, data=Gender1))
summary(fit)
confint(fit, level=0.95)
plot(fit)
 cor(Gender1$total_ns_cv,Gender1$hgb_difference ,  method = "pearson", use = "complete.obs")
library("ggpubr")
ggscatter(Gender1, x = "total_ns_cv", y = "hgb_difference", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Total fluid (ml)", ylab = "Change in hemoglobin")
```

For new table data for the 

```{r}
dfr <- data.frame(newtable)
# 

  
dfr[order(dfr$charttime),] 
dfr %>%
  separate(charttime, c("date", "time"), " ") %>%
  dfr[order(dfr$date),]




```

##manipulating the height and weight 

```{r}
library("plyr")
meanwt <- ddply(Weight, .(icustay_id), summarise, mean_wt=mean(Weight))
meanht <- ddply(Height, .(icustay_id), summarise, mean_ht=mean(Height)) 
meanage <- ddply(Age, .(icustay_id), summarise, mean_age = mean(age))

compl<- merge (Gender, meanwt, all.x = T)
Comple <- merge (compl, meanht, all.x = T)
complete <- merge (Comple, meanage, all.x = T)



# library(dplyr)
# subset(tab, icustay_id %in% fframe2$icustay_id)

complete$fluidwt= complete$total_ns_cv/complete$mean_wt


library(dplyr)
library(tidyverse)
complete%>% filter(total_ns_cv <8000)%>% filter(fluidwt <500)%>%
  ggplot(aes(x = hgb_difference, y= fluidwt)) +
  geom_point(color = "black") +
  xlab("difference") +
  ylab("total fluid by weight")+
  ggtitle("Preliminary exploration")
completamente <-complete%>% filter(total_ns_cv <8000) %>% filter(fluidwt <500)
(fit1<-lm( completamente$hgb_difference ~ completamente$fluidwt))
summary(fit1)
cor(completamente$fluidwt,completamente$hgb_difference ,  method = "pearson", use = "complete.obs")
library("ggpubr")

ggscatter(data=completamente, x = "total_ns_cv", y = "hgb_difference", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Total fluid (ml)", ylab = "Change in hemoglobin")

```


## FOR RUNNING RANDOM FOREST MODEL - Attempt 1

```{r}
install.packages("randomForest")
library(randomForest)
set.seed(100)
mydata = completamente %>% mutate_if(is.character, as.factor)
dim(mydata)
str(mydata)
train <- sample(nrow(mydata), 0.75*nrow(mydata), replace = TRUE)
TrainSet <- mydata[train,]
ValidSet <- mydata[-train,]
summary(TrainSet)
summary(ValidSet)

model1 <- randomForest(hgb_difference ~ ., data = TrainSet, importance = TRUE)
model1
model2 <- randomForest(hgb_difference ~ ., data = TrainSet, ntree = 500, mtry = 4, importance = TRUE, na.action = na.omit)
model2
plot(model2)

# Predicting on train set
TrainSet$predTrain <- predict(model2, TrainSet, type = "class")
# Checking classification accuracy
table(predTrain, TrainSet$Condition) 
```

## Code randomforest from class - Attempt 2
```{r}
completamente = completamente %>% mutate_if(is.character, as.factor)

cor(complete$hr,complete$hgb_difference)

complete.rf<-randomForest(as.numeric(hgb_difference)~as.numeric(completamente$total_ns_cv)+as.numeric(completamente$hr)+factor(completamente$Gender)+as.numeric(completamente$mean_age),data=completamente)

set.seed(1123)
control <- trainControl(method="repeatedcv", number=5, repeats=3, classProbs = TRUE, summaryFunction = twoClassSummary)
modelTree <- train(hgb_difference~., data=completamente, method="rpart", metric="class", trControl=control)
modelRF <- train(hgb_difference~., data= completamente, method="rf", metric="ROC", trControl=control)
# train the GBM In.hospital_death (with xgboost)
modelGbm <- train(death~., data=seta, method="xgbTree", metric="ROC", trControl=control, verbose=FALSE)
# summarize the distributions
summary(results)
# boxplots of results
bwplot(results)
# dot plots of results
dotplot(results)
```

##Attempt at randomforest- Attemp 3
```{r}
library(rsample)      # data splitting 
library(randomForest) # basic implementation
library(ranger)       # a faster implementation of randomForest
library(caret)        # an aggregator package for performing many machine learning models
library(h2o)          # an extremely fast java-based platform
complete = complete %>% mutate_if(is.character, as.factor)
str(complete)
drop_columns <- c("first_measurement", "last_measurement", "mean_wt", "mean_ht","fluidwt")
com <- complete[, !(names(complete) %in% drop_columns)]
head(com)
set.seed(123)
com_split <- initial_split(com, prop = .7)
com_train <- training(com_split)
com_test  <- testing(com_split)
```

```{r}


m1 <- randomForest(formula = hgb_difference ~ ., 
                   data = com, na.action = na.roughfix)
m1
plot(m1)

```
```{r}
which.min(m1$mse)
sqrt(m1$mse[which.min(m1$mse)])
```
```{r}
set.seed(123)
valid_split <- initial_split(com, .8)
com_train_v2 <- analysis(valid_split)
com_valid <- assessment(valid_split)
x_test <- com_valid[setdiff(names(com_valid), "hgb_difference")]
y_test <- com_valid$hgb_difference
str(x_test)
str(y_test)
rf_oob_comp <- randomForest(
  formula = hgb_difference ~ .,
  na.action = na.roughfix,
  data    = com_train_v2,
  xtest   = x_test,
  ytest   = y_test
)
oob <- sqrt(rf_oob_comp$mse)
validation <- sqrt(rf_oob_comp$test$mse)
tibble::tibble(
  `Out of Bag Error` = oob,
  `Test error` = validation,
  ntrees = 1:rf_oob_comp$ntree
) %>%
  gather(Metric, RMSE, -ntrees) %>%
  ggplot(aes(ntrees, RMSE, color = Metric)) +
  geom_line() +
  scale_y_continuous(labels = scales::dollar) +
  xlab("Number of trees")
```

tuning
```{r}
features <- setdiff(names(com_train), "hgb_difference")

set.seed(123)

m2 <- tuneRF(
  x          = com_train[features],
  y          = com_train$hgb_difference,
  ntreeTry   = 500,
  mtryStart  = 5,
  stepFactor = 1.5,
  improve    = 0.01,
  trace      = FALSE      # to not show real-time progress 
)
```
create hypergrid
```{r}
hyper_grid <- expand.grid(
  mtry       = seq(0, 9, by = 1),
  node_size  = seq(3, 9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)
nrow(hyper_grid)
for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = hgb_difference~ ., 
    data            = com_train, 
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}
hist(hyper_grid$OOB_RMSE)
hyper_grid %>% 
 dplyr::arrange(OOB_RMSE) %>%
  head(10)
```



